{
  "hash": "63ea3ae3f0b6cb6ee1f48d61ab9c96a3",
  "result": {
    "markdown": "---\ntitle: \"Make Scikit-Learn faster using only two lines of code\"\nauthor: \"Mohammed Hamdy\"\ndate: \"2022-12-19\"\ncategories: [scikit-learn, python]\n---\n\nYes! and no GPU involved. Intel has made an extension that can accelerate your scikit-learn code without any change to scikit-learn's api. This means that you can apply it to an already existing code without changing anything and still get an enhanced performance.\n\n## How does this work?\n\nBasically Intel has wrote its own CPU optimized algorithms but kept full conformance with all Scikit-Learn APIs and algorithms. What the introduced code does is replace Scikit-Learn's algorithms with Intel's new optimized versions of these algorithms. This is also known as **patching**.\n\nSo, does it work?. Let's see how *KMeans* is doing, starting with creating our own synthetic dataset of 10 million samples using Scikit-Learn's `make_blobs`.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nfrom sklearn.datasets import make_blobs\n\nX, y = make_blobs(n_samples = 10_000_000, \n                  centers = 15, \n                  n_features = 2, \n                  random_state = 42)\n```\n:::\n\n\nNow all we need to do in order to use the optimized algorithm is to import the patch and use it.\n\n::: {.callout-note}\nMake sure to import scikit-learn after importing and calling the patch. Otherwise, the patching will not affect the original scikit-learn estimators.\n:::\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nfrom sklearnex import patch_sklearn\npatch_sklearn()\n\nfrom sklearn.cluster import KMeans\nfrom timeit import default_timer as timer\n\nstart = timer()\nkmeans = KMeans(n_clusters=15, random_state=12).fit(X)\ntime_diff = timer() - start\nf\"The elapsed time for the optimized model is: {time_diff:.2f} s\"\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nIntel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=2}\n```\n'The elapsed time for the optimized model is: 24.09 s'\n```\n:::\n:::\n\n\nBut what about the original algorithm?\n\nTo get back to using our original Scikit-Learn algorithms, all we need to do is just opt out of using the patch by simply **unpatching**.\nAgain, make sure to reimport Scikit-Learn after you unpatch.\n\nLet's now see how much time will it take the original algorithm.\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nfrom sklearnex import unpatch_sklearn\nunpatch_sklearn()\n\nfrom sklearn.cluster import KMeans\n\nstart = timer()\nkmeans = KMeans(n_clusters=15, random_state=12).fit(X)\ntime_diff = timer() - start\nf\"The elapsed time for Scikit-Learn's original model is: {time_diff:.2f} s\"\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```\n\"The elapsed time for Scikit-Learn's original model is: 239.38 s\"\n```\n:::\n:::\n\n\nThe optimized algorithm is almost 10 times faster than the original one. For more informative comparison, check [Benchmarking Intel Extension for Scikit-learn](https://www.intel.com/content/www/us/en/developer/articles/technical/benchmarking-intel-extension-for-scikit-learn.html) article by Intel.\n\n## This is great but...\n\nUnfortunately, not all algorithms in Scikit-Learn are affected by the patch. For a list of supported algorithms check: [Supported Algorithms](https://intel.github.io/scikit-learn-intelex/algorithms.html)\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}