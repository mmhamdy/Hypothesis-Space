[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Helloüëã, and welcome to Hypothesis Space üåå\nI‚Äôm Mohammed Hamdy. I live in Cairo, Egypt. For the most part of my professional career I‚Äôve been working as a preclinical research scientist. I‚Äôve been studying machine learning for a while now, and in this blog I intend to write about things that I find interesting in the field, or some useful programming tips that I‚Äôve stumbled upon, or even just my thoughts on different matters.\nIn machine learning, I‚Äôm particularly interested in neural network compression, continual learning, and self-supervised learning. A field that I find really promising and hope to get a chance to read more about someday is graph neural networks.\nI‚Äôm also interested in the applications of machine learning and natural language processing in biology. Specifically, I‚Äôm interested in protein and genomics language models.\nThings that I enjoy doing include:\n\nReading üìö: I enjoy reading all sorts of books, but my favorite genres are science fiction and philosophy. My favorite science fiction novels are: Consider Phlebas, and The Metamrphosis of Prime Intellect. Two novels in which we live in harmony with AI (sort of).\nAimless walking üö∂ and weird discussions with friends.\nWatching and talking about films üé•. My favorite film directors are: Coen Brothers, Tim Burton, and Werner Herzog.\nEating Pizza üçï\n\nTrivia Time: In Antarctica, there is a mountain named Mount Hypothesis in appreciation of the role of hypothesis in scientific research."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Hypothesis Space",
    "section": "",
    "text": "Faster Scikit-Learn using only two lines of code\n\n\n\n\n\n\n\nscikit-learn\n\n\npython\n\n\n\n\nAccelerate Scikit-Learn algorithms using Intel‚Äôs CPU optimized code and get 10x faster results.\n\n\n\n\n\n\nDec 19, 2022\n\n\nMohammed Hamdy\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/faster_sklearn/index.html",
    "href": "posts/faster_sklearn/index.html",
    "title": "Faster Scikit-Learn using only two lines of code",
    "section": "",
    "text": "Yes! and no GPU involved. Intel has made an extension that can accelerate your scikit-learn code without any change to scikit-learn‚Äôs api. This means that you can apply it to an already existing code without changing anything and still get an enhanced performance."
  },
  {
    "objectID": "posts/faster_sklearn/index.html#how-does-this-work",
    "href": "posts/faster_sklearn/index.html#how-does-this-work",
    "title": "Faster Scikit-Learn using only two lines of code",
    "section": "How does this work?",
    "text": "How does this work?\nBasically Intel has wrote its own CPU optimized algorithms but kept full conformance with all Scikit-Learn APIs and algorithms. What the introduced code does is replace Scikit-Learn‚Äôs algorithms with Intel‚Äôs new optimized versions of these algorithms. This is also known as patching.\nSo, does it work?. Let‚Äôs see how KMeans is doing, starting with creating our own synthetic dataset of 10 million samples using Scikit-Learn‚Äôs make_blobs.\n\nfrom sklearn.datasets import make_blobs\n\nX, y = make_blobs(n_samples = 10_000_000, \n                  centers = 15, \n                  n_features = 2, \n                  random_state = 42)\n\nNow all we need to do in order to use the optimized algorithm is to import the patch and use it.\n\n\n\n\n\n\nNote\n\n\n\nMake sure to import scikit-learn after importing and calling the patch. Otherwise, the patching will not affect the original scikit-learn estimators.\n\n\n\nfrom sklearnex import patch_sklearn\npatch_sklearn()\n\nfrom sklearn.cluster import KMeans\nfrom timeit import default_timer as timer\n\nstart = timer()\nkmeans = KMeans(n_clusters=15, random_state=12).fit(X)\ntime_diff = timer() - start\nf\"The elapsed time for the optimized model is: {time_diff:.2f} s\"\n\nIntel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n\n\n'The elapsed time for the optimized model is: 24.25 s'\n\n\nBut what about the original algorithm?\nTo get back to using our original Scikit-Learn algorithms, all we need to do is just opt out of using the patch by simply unpatching. Again, make sure to reimport Scikit-Learn after you unpatch.\nLet‚Äôs now see how much time will it take the original algorithm.\n\nfrom sklearnex import unpatch_sklearn\nunpatch_sklearn()\n\nfrom sklearn.cluster import KMeans\n\nstart = timer()\nkmeans = KMeans(n_clusters=15, random_state=12).fit(X)\ntime_diff = timer() - start\nf\"The elapsed time for Scikit-Learn's original model is: {time_diff:.2f} s\"\n\n\"The elapsed time for Scikit-Learn's original model is: 254.50 s\"\n\n\nThe optimized algorithm is almost 10 times faster than the original one. For more informative comparison, check Benchmarking Intel Extension for Scikit-learn article by Intel."
  },
  {
    "objectID": "posts/faster_sklearn/index.html#this-is-great-but",
    "href": "posts/faster_sklearn/index.html#this-is-great-but",
    "title": "Faster Scikit-Learn using only two lines of code",
    "section": "This is great but‚Ä¶",
    "text": "This is great but‚Ä¶\nUnfortunately, not all algorithms in Scikit-Learn are affected by the patch. For a list of supported algorithms check: Supported Algorithms"
  }
]